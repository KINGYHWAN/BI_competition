{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["KcKY4XT5az0_","LO7dw-cga79k","4SaovodibbyS","hBNfYKDzDZlR"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Importing 및 세팅용 함수, 지역명 ID\n","\n"," - find_missing_dates(df) 빈 날짜 찾아내 리스트로 저장\n"," - intervalization(list) 연속값을 구간을 나눠 각 구간의 시작, 끝, 길이를 저장\n"," - whtdata('지역명',시작,끝,길이) API 호출 함수\n"," <br>\n","\n"," - ID에 지역명 지역정보 저장"],"metadata":{"id":"KcKY4XT5az0_"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kFknaInr6x3h","executionInfo":{"status":"ok","timestamp":1687225579029,"user_tz":-540,"elapsed":20709,"user":{"displayName":"정민균","userId":"02008085652330605669"}},"outputId":"92db1e73-eb0b-4007-d26c-b8663e6d2b28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import inspect\n","from datetime import datetime, timedelta\n","import requests\n","import pprint\n","import bs4\n","from lxml import html\n","from urllib.parse import urlencode, quote_plus, unquote\n","import pandas as pd"],"metadata":{"id":"i-b93jprJQil"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 딕셔너리에 key : '지역명' value = [지역별 검색 번호, '지역 영문명'] 으로 저장,\n","# API 호출 함수에서 '지역명' 입력하면 자동으로 지역 검색번호 입력하고, 나중에 파일 저장 시 '영문명_df' 로 저장하기위해 만들어 놓음\n","\n","ID={\n","  # 특별, 광역 시\n","    '서울' : [108, 'seoul'], '부산' : [159, 'busan'], '대구' : [143, 'daegu'], '인천' : [112, 'incheon'],\n","    '광주' : [156, 'gwangju'], '대전' : [133, 'daejeon'], '울산' : [152, 'woolsan'], '세종' : [239, 'saejong'],\n","  # 경기도 지역은 뒤에 _Gg\n","    '수원' : [119, 'suwon_Gg'], '파주' : [99, 'paju_Gg'], '양평' : [202, 'yangpyeong_Gg'], '동두천' : [98, 'dongducheon_Gg'],\n","  # 강원도 지역은 뒤에 _Gw\n","    '태백' : [216, 'taebaek_Gw'], '원주' : [114, 'wonju_Gw'], '철원' : [95, 'cheolwon_Gw'], '속초' : [90, 'sokcho_Gw'],\n","  # 충청도 지역은 뒤에 _Cc\n","    '서산' : [129, 'seosan_Cc'], '부여' : [236, 'buyeo_Cc'], '금산' : [238, 'geumsan_Cc'], '제천' : [221, 'jecheon_Cc'],\n","  # 전라도 지역은 뒤에 _Jl\n","    '여수' : [168, 'yeosu_Jl'], '해남' : [261, 'haenam_Jl'], '군산' : [140, 'gunsan_Jl'], '장수' : [248, 'jangsu_Jl'],\n","  # 경상도 지역은 뒤에 _Ks\n","    '울진' : [130, 'wooljin_Ks'], '상주' : [137, 'sangju_Ks'], '남해' : [295, 'namhae_Ks'], '김해' : [253, 'gimhae_Ks'],\n","  # 제주도 지역은 뒤에 _Jj\n","    '제주' : [184, 'jeju_Jj'], '서귀포' : [189, 'seoguipo_Jj'],\n","  # 프로젝트 중간에 추가 수집 하기로 한 지역이라 뒤에 _도명 이름이 위에랑 다름\n","    '경주' : [283, 'gyeongju_KB'], '구미' : [279, 'gumi_KB'], '거창' : [284, 'geochang_KN'], '밀양' : [288, 'milyang_KN'],\n","    '영광' : [252, 'yeonggwang_JN'], '순천' : [174, 'sooncheon_JN'], '남원' : [247, 'namwon_JB'], '고창' : [251, 'gochang_JB'],\n","    '천안' : [232, 'cheonahn_CN'], '보은' : [226, 'boeun_CB'], '청주' : [131, 'cheongju_CB']\n","}"],"metadata":{"id":"Sx38E6siet-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def find_missing_dates(df):\n","    start_date = datetime(2012, 1, 1, 0)\n","    end_date = datetime(2023, 3, 31, 0)\n","\n","    # 우선 1시간 단위로 2012-01-01 00시 ~ 2023-03-31 00시 까지의 날짜를 모아놓은 set 생성\n","    # 모든 날짜에 대해 순회 해야하기 때문에 검색이 빠른 set 사용\n","    date_set = set()\n","    current_date = start_date\n","    while current_date <= end_date:\n","        date_set.add(current_date.strftime('%Y%m%d-%H'))\n","        current_date += timedelta(hours=1)\n","\n","    # 데이터프레임을 순회하며 존재하는 날짜 제거\n","    for _, row in df.iterrows():\n","        time_value = row['시간']\n","        if isinstance(time_value, pd.Timestamp):\n","            time_value = time_value.strftime('%Y-%m-%d %H:%M')\n","        else:\n","            time_value = str(time_value)\n","        time_value = datetime.strptime(time_value, '%Y-%m-%d %H:%M').strftime('%Y%m%d-%H')\n","        if time_value in date_set:\n","            date_set.remove(time_value)\n","\n","    # 데이터프레임에 존재하지 않는 시간대가 정렬된 set으로 반환\n","    missing_dates = sorted(date_set)\n","    return missing_dates"],"metadata":{"id":"lDxjVizrbNyi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 어쨌든 수집되지 않은 날짜는 다시 수집을 해야하는데,\n","# 이전에 만들어 놓은 API 호출함수는 whtdata(지역명, 수집할 일 수, 시작일) 의 구조기 때문에\n","# 수집되지 않은 구간을 세부적으로 구간화 해보고 구간정보를 trigger 라는 리스트에 저장 할 것이다.\n","\n","    # trigger에 저장할때, (구간 시작 시간, 구간 끝 시간, 구간내 시간 수)\n","\n","def intervalization(missing_dates):\n","  missing_dates.append('20230614-00')\n","  count=1\n","  trigger=[]\n","  for _ in range(len(missing_dates)-1):\n","    format_str='%Y%m%d-%H'\n","    date1=datetime.strptime(missing_dates[_], format_str)\n","    date2=datetime.strptime(missing_dates[_+1], format_str)\n","\n","    # 또한 호출 시에 1000개를 넘어가면 안되니까 984개가 넘어가면 구간을 다시 규정하도록 해주었음\n","    if date1+timedelta(hours=1) == date2 and count<984:\n","      count+=1\n","    else:\n","      trigger.append((missing_dates[_-count+1],missing_dates[_], count))\n","      count=1\n","  return trigger"],"metadata":{"id":"ypH_sDPxmGER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 인증키는 파라미터로 사용할거라서 encoding 이나 decoding에 저장해놓기\n","\n","    # 아래 인증키는 예시로 실제로는 존재하지 않는 값으로 바꿔 놓은거에요 실제로 하려면 API Key 발급 받으세용\n","\n","# 인증키 입력\n","encoding = 'krXiIV2saGLs2q0y37QxMoocEgXWyj53g8a%2F1XlpuLMgpEhzE5BkI8N9ogyg4ykq4W5FvysQsUOY8wQ%3D%3D'\n","decoding = 'krXisaGLs2q0y37QxvGMoocEgXWyj53g8a/1XlgpEhzEt15BkI8N9ogyg4ykq4tXWW5FvyOY8wQ=='"],"metadata":{"id":"KAwWhP-QYMzP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# whtdata 함수는 동일함\n","\n","# 지역, 시작일, 끝일을 입력하면 받아지도록 함수 설정\n","def whtdata(stNm, date, start):\n","  global ID\n","  # API 가져오는 기본 URL 중간중간 {} 에는 특정 파라미터를 입력해야함\n","  base_url = 'http://apis.data.go.kr/1360000/AsosHourlyInfoService/getWthrDataList?serviceKey={serviceKey}&numOfRows={numOfRows}&pageNo={pageNo}&dataCd={dataCd}&dateCd={dateCd}&stnIds={stnIds}&endDt={endDt}&endHh={endHh}&startHh={startHh}&startDt={startDt}'\n","\n","  # 입력해야할 파라미터 들 입력\n","  params = {\n","      \"serviceKey\": encoding,\n","      \"numOfRows\": date,# 한번에 가져올 날짜 정보 개수는 1000개를 넘어갈 수 없음, 그래서 984개(41일치) 입력했음 중간중간\n","      \"pageNo\": '1',\n","      \"dataCd\": \"ASOS\",\n","      \"dateCd\": \"HR\", # 시간단위\n","      \"stnIds\": ID[stNm][0], # 지역 번호\n","      \"endDt\": '20230331', # 끝날짜\n","      \"endHh\": \"01\", # 끝 시간대\n","      \"startHh\": \"00\", # 시작시간대\n","      \"startDt\": start # 시작 날짜\n","  }\n","  # formatting으로 url 정하기, (함수 변수 넣기)\n","  url = base_url.format(**params)\n","\n","  # url에서 정보 가져오기\n","  response = requests.get(url)\n","\n","  # 가져온 정보에서 xml 추출, 갖고싶은 기상정보들은 item에 있음\n","  content = response.text\n","  xml_obj = bs4.BeautifulSoup(content,'lxml-xml')\n","  te = xml_obj.find_all('item')\n","  datas = [] # 담아놓을 2차원 리스트\n","\n","  # te 정보 리스트에 몽땅 담기\n","    # 이때 if, else로 서버의 순간 오류로 빈 값이 오게 될때 for문이 멈추지 않도록 함\n","    # 데이터 양이 너무 방대해 서버가 순간 끊기는 경우가 반드시 발생함 (이렇게 빈 값이 오는 경우는 나중에 채워준다)\n","  for i in range(len(te)):\n","      tm = te[i].tm.string.strip() if te[i].tm and te[i].tm.string else \"\"\n","      stnNm = te[i].stnNm.string.strip() if te[i].stnNm and te[i].stnNm.string else \"\"\n","      ta = te[i].ta.string.strip() if te[i].ta and te[i].ta.string else \"\"\n","      rn = te[i].rn.string.strip() if te[i].rn and te[i].rn.string else \"\"\n","      hm = te[i].hm.string.strip() if te[i].hm and te[i].hm.string else \"\"\n","      ss = te[i].ss.string.strip() if te[i].ss and te[i].ss.string else \"\"\n","      icsr = te[i].icsr.string.strip() if te[i].icsr and te[i].icsr.string else \"\"\n","      dsnw = te[i].dsnw.string.strip() if te[i].dsnw and te[i].dsnw.string else \"\"\n","\n","      data = [tm, stnNm, ta, rn, hm, ss, icsr, dsnw]\n","      # 2차원 리스트에 저장\n","      datas.append(data)\n","\n","  # 2차원 리스트 쌓아 놓은 것 ex_df로 데이터프레임화\n","  ex_df=pd.DataFrame(datas, columns=['시간','지역명','기온','강수량','습도','일조','일사','적설'])\n","\n","  return ex_df\n","\n","# 원래 이 API에서 가져올 수있는 모든 기상정보 변수는 아래와 같음\n","# data = [tm, stnId, stnNm, ta, taQcflg, rn, rnQcflg, ws, wsQcflg, wd, wdQcflg, hm, hmQcflg, pv, td, pa, paQcflg, ps,\n","#         psQcflg, ss, ssQcflg, icsr, dsnw, hr3Fhsc, dc10Tca, dc10LmcsCa, clfmAbbrCd, lcsCh, vs, gndSttCd, dmstMtphNo, ts, tsQcflg,\n","#         m005Te, m01Te, m02Te, m03Te]"],"metadata":{"id":"gFMZ4J2-YRK2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 채우기 + 저장 fill_dates 함수\n","- fill_dates('지역명' , 0 ,pd.DataFrame())\n","\n","- 내부에서 결측 날짜 리스트 수집 > 구간화 <br> > 구간 값으로 API 호출 (반복문으로 전부 합치기)\n","\n","- 만일 호출이 중간에 누락되어 받아지지 않은 경우에 다시 재귀적으로 함수를 돌리도록 구성\n","\n","- fill_dates 함수는 24개보다 많은 구간만 API로 채워옴\n","\n","# 이제 24개 이하 값들 전부 채우는 함수 fill_NaN_dates\n","\n","- 앞의 함수에서 큰 구간값이 채워지고, 결측 구간을 전달받아 그 값으로 운용\n","\n","- 최종 데이터프레임의 크기, 결측값 개수 출력및 드라이브에 저장"],"metadata":{"id":"LO7dw-cga79k"}},{"cell_type":"code","source":["# 재수집 하고 그래도 수집 안된녀석이 있으면 재수집 : 재수집 회수를 저장, 출력을 위해 count 사용 (시작은 0)\n","\n","def fill_dates(stNm, count, data):\n","  # count 0이면 재수집 이뤄지기 전에는 드라이브에서 가져오기\n","  if count==0:\n","    ndf=pd.read_csv('/content/drive/MyDrive/2023 겨울학기 + 여름학기/B.I Contest/데이터/지역별 기상데이터 모음/1차 수집/{}_df.csv'.format(ID[stNm][1]))\n","  # count 0아니면 재재수집 이상 이니까 그냥 가져와서 만들기\n","  else:\n","    ndf=data\n","\n","  # 재수집 전에 크기 확인\n","  print(\"{}번쨰\".format(count),stNm,\"API 불러와 결측치 처리 전 데잍 프레임의 크기 :\", ndf.shape)\n","  nums_instance_org_df=int(ndf.shape[0])\n","  # 변수 저장해놓은 다음에 수집안된 날짜 구간화해서 저장\n","  miss_dates=intervalization(find_missing_dates(ndf))\n","\n","  # 구간의 개수출력\n","  print(\"{}번쨰\".format(count),stNm,\"만들어질 날짜 구간의 개수 :\",len(miss_dates))\n","\n","  # 재수집 이전 깡통 df, 각 변수 초기화\n","  df=pd.DataFrame()\n","  nums=0\n","  made_inst=0\n","\n","  # 수집되지 않은 기간 확인해보니 대부분이 1일(24시간) 치가 누락되고 1일 이상 누락된 것은 30일 씩, 이렇게 큰단위였음\n","  # 그래서 큰 단위의 재수집을 따로 진행한 후에, 1일치를 따로 진행 하고자 하였음\n","  for _ in miss_dates:\n","    # 구간 중에서 24개 넘는거 (큰단위) 재수집하기\n","    if _[2] > 24:\n","      df=pd.concat([df,whtdata(stNm,_[0][0:8], _[1][0:8], _[2])], axis=0)\n","      nums+=1\n","      made_inst+=int(_[2])\n","  # 24개 넘는 구간 개수와, 그 구간이 채워지면서 얼마의 시간이 추가되었는지 출력\n","  print(\"{}번쨰\".format(count),stNm,\"구간 중 24시간 이상인 구간의 개수 :\",nums)\n","  print(\"{}번째\".format(count),stNm,\"새롭게 만들어진 instance의 개수 :\",made_inst)\n","\n","  # 재수집한 데이터 프레임 합치고 정렬, 인덱스 재정의\n","  ndf=pd.concat([ndf, df],axis=0)\n","  ndf['시간'] = pd.to_datetime(ndf['시간'])\n","  ndf = ndf.sort_values(by='시간')\n","  ndf=ndf.reset_index(drop=True)\n","\n","  # 재수집된 날짜를 봤는데 24시간 이상 수집되었을 때의 날짜보다 적으면 수집이 제대로 안된거니까 재 수집 진행\n","  if ndf.shape[0] < nums_instance_org_df+made_inst:\n","    print(\"누락된 수집이 있어 재 수집 합니다. {} 번째 재수집입니다.\".format(count),'\\n')\n","    # recursive 하게 count+1 해서 진행\n","    fill_dates(stNm, count+1, ndf)\n","\n","  # 아니면 결론 출력하기\n","  else:\n","    print('\\n',stNm, \"편집되어 채워진 데이터프레임의 크기 :\",ndf.shape,'\\n','만들어진 데이터프레임 결측처리가 안된 instance 개수 :', ndf['지역명'].isnull().sum(),'\\n')\n","\n","  # 채워진 ndf, 그리고 아직 24개씩 비워진건 안채웠으니, 빈 날짜 리스트, 지역명 반환\n","  return ndf, miss_dates, stNm"],"metadata":{"id":"XOc31Taj17Pw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이제 24개 이하씩 비워진거 채우기\n","\n","# 어쩌다보니 위와 로직이 좀 다른데 전체적으로 봤을 때, 위에서는 그냥 날짜 재수집 한다음에 붙이고 정렬했음\n","# 그리고 하루치 기상 정보는 그냥 이전 값 일의 값을 가져오는 것으로 고려했음\n","\n","def fill_NaN_dates(ndf, miss_dates, stNm):\n","    # 빈날짜 채우고 빈칸으로 만들어 놓기\n","    start_date = pd.to_datetime('2012-01-01 00:00')\n","    end_date = pd.to_datetime('2023-03-31 00:00')\n","\n","    all_dates = pd.date_range(start=start_date, end=end_date, freq=\"H\")\n","\n","    df_all_dates = pd.DataFrame({\"시간\": all_dates})\n","    ndf[\"시간\"] = pd.to_datetime(ndf[\"시간\"])\n","\n","    df_all_dates = pd.merge(df_all_dates, ndf, on=\"시간\", how=\"left\")\n","    df_all_dates = df_all_dates.fillna(0)\n","\n","    # 이제 24개 미만인것들을 채워보자\n","    for __ in miss_dates:\n","        if __[2] <= 24:\n","            dates = __[0]\n","            for _ in range(__[2]):\n","                time_value = datetime.strptime(dates, '%Y%m%d-%H')\n","                after_day = time_value + timedelta(days=1)\n","                before_day = time_value - timedelta(days=1)\n","\n","                target_time = time_value.strftime('%Y-%m-%d %H:%M:%S')\n","                after_time = after_day.strftime('%Y-%m-%d %H:%M:%S')\n","                before_time = before_day.strftime('%Y-%m-%d %H:%M:%S')\n","\n","                # 변경할 값을 가져오기 하루 전날 값으로 가져오기\n","                if target_time[:10] == '2023-03-30' or target_time[:10] == '2023-03-31' :\n","                    replace_values = {\n","                        '지역명': df_all_dates.loc[df_all_dates['시간'] == before_time, '지역명'].values[0],\n","                        '기온': df_all_dates.loc[df_all_dates['시간'] == before_time, '기온'].values[0],\n","                        '강수량': df_all_dates.loc[df_all_dates['시간'] == before_time, '강수량'].values[0],\n","                        '습도': df_all_dates.loc[df_all_dates['시간'] == before_time, '습도'].values[0],\n","                        '일조': df_all_dates.loc[df_all_dates['시간'] == before_time, '일조'].values[0],\n","                        '일사': df_all_dates.loc[df_all_dates['시간'] == before_time, '일사'].values[0],\n","                        '적설': df_all_dates.loc[df_all_dates['시간'] == before_time, '적설'].values[0]\n","                    }\n","                else:\n","                    replace_values = {\n","                        '지역명': df_all_dates.loc[df_all_dates['시간'] == after_time, '지역명'].values[0],\n","                        '기온': df_all_dates.loc[df_all_dates['시간'] == after_time, '기온'].values[0],\n","                        '강수량': df_all_dates.loc[df_all_dates['시간'] == after_time, '강수량'].values[0],\n","                        '습도': df_all_dates.loc[df_all_dates['시간'] == after_time, '습도'].values[0],\n","                        '일조': df_all_dates.loc[df_all_dates['시간'] == after_time, '일조'].values[0],\n","                        '일사': df_all_dates.loc[df_all_dates['시간'] == after_time, '일사'].values[0],\n","                        '적설': df_all_dates.loc[df_all_dates['시간'] == after_time, '적설'].values[0]\n","                    }\n","\n","                # 값 변경\n","                df_all_dates.loc[df_all_dates['시간'] == target_time, ['지역명', '기온', '강수량', '습도', '일조', '일사', '적설']] = replace_values.values()\n","\n","                dates = (time_value + timedelta(hours=1)).strftime('%Y%m%d-%H')\n","\n","    # 전부 채워진 데이터는 다시 저장\n","    df_all_dates.to_csv('/content/drive/MyDrive/2023 겨울학기 + 여름학기/B.I Contest/데이터/지역별 기상데이터 모음/결측값 채워진 df/filled_{}_df.csv'.format(ID[stNm][1]), index=False)\n","    return print(df_all_dates.isnull().sum(), df_all_dates.shape, sep='\\n')"],"metadata":{"id":"y4Se7oQVpnO6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 수집하기\n","\n","\n"," - 1차 수집 완료\n"," - 구, 도 별로 나눠서 저장 (한번에 하면 너무 오래걸려)\n","\n","# 수집방법\n","\n"," - a,b,c= fill_dates('지역명', 0, pd.DataFrame())\n"," - fill_NaN_dates(a,b,c) 하면 드라이브에 자동 저장\n"],"metadata":{"id":"4SaovodibbyS"}},{"cell_type":"code","source":["# 빈날짜를 채워보자\n","\n","special = ['서울','인천','광주','대구','부산','울산','세종','대전'] # 특별시\n","Gg = ['파주','양평','수원','동두천']  # 경기\n","Gw = ['태백','원주','철원','속초']    # 강원\n","Cc = ['서산','부여','금산','제천']    # 충청\n","Jl = ['여수','장수','해남','군산']    # 전라\n","Gn = ['남해','김해','울진','상주']    # 경상\n","Jj = ['제주','서귀포']                # 제주\n","State_Name=['경주','구미','거창','밀양','영광','순천','남원','고창','천안','보은','청주'] # 추가 지역"],"metadata":{"id":"tRIV7uJXa9WP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 예시로 제주지역 채우는 장면\n","\n","for state in Jj:\n","  # 24 개 이상을 채운 결과 a, b, c에 받고\n","  a, b, c= fill_dates(state ,0 ,pd.DataFrame())\n","\n","  # 24개 미만은 그냥 전날 값 으로 대체\n","  fill_NaN_dates(a, b, c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CiVe6EOYcy_D","executionInfo":{"status":"ok","timestamp":1686812445357,"user_tz":-540,"elapsed":178700,"user":{"displayName":"정민균","userId":"02008085652330605669"}},"outputId":"8923a513-dda8-4583-8475-6bf812b101e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0번쨰 제주 API 불러와 결측치 처리 전 데잍 프레임의 크기 : (91345, 8)\n","0번쨰 제주 만들어진 날짜 구간의 개수 : 103\n","0번쨰 제주 구간 중 24시간 이상인 구간의 개수 : 5\n","0번째 제주 새롭게 만들어진 instance의 개수 : 4920\n","\n"," 제주 편집되어 채워진 데이터프레임의 크기 : (96265, 8) \n"," 만들어진 데이터프레임 결측처리가 안된 instance 개수 : 0 \n","\n","시간     0\n","지역명    0\n","기온     0\n","강수량    0\n","습도     0\n","일조     0\n","일사     0\n","적설     0\n","dtype: int64\n","(98569, 8)\n","0번쨰 서귀포 API 불러와 결측치 처리 전 데잍 프레임의 크기 : (82705, 8)\n","0번쨰 서귀포 만들어진 날짜 구간의 개수 : 106\n","0번쨰 서귀포 구간 중 24시간 이상인 구간의 개수 : 14\n","0번째 서귀포 새롭게 만들어진 instance의 개수 : 13776\n","\n"," 서귀포 편집되어 채워진 데이터프레임의 크기 : (96481, 8) \n"," 만들어진 데이터프레임 결측처리가 안된 instance 개수 : 0 \n","\n","시간     0\n","지역명    0\n","기온     0\n","강수량    0\n","습도     0\n","일조     0\n","일사     0\n","적설     0\n","dtype: int64\n","(98569, 8)\n"]}]},{"cell_type":"markdown","source":["# 만들어진 데이터프레임의 크기를 확인해보자"],"metadata":{"id":"hBNfYKDzDZlR"}},{"cell_type":"code","source":["for _ in Stage_Completed:\n","  df=pd.read_csv('/content/drive/MyDrive/2023 겨울학기 + 여름학기/B.I Contest/데이터/지역별 기상데이터 모음/결측값 채워진 df/filled_{}_df.csv'.format(ID[_][1]))\n","  print(\"결측 날짜까지 만들어진 {} 지역의 instance 개수 : \".format(_),df.shape[0], '\\n')"],"metadata":{"id":"8u0JwmCq4OXu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686883011583,"user_tz":-540,"elapsed":12235,"user":{"displayName":"정민균","userId":"02008085652330605669"}},"outputId":"bfe5a21b-7af7-4877-a51e-732832c09dd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["결측 날짜까지 만들어진 제주 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 서귀포 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 남해 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 울진 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 상주 지역의 instance 개수 :  98572 \n","\n","결측 날짜까지 만들어진 김해 지역의 instance 개수 :  98581 \n","\n","결측 날짜까지 만들어진 여수 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 장수 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 해남 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 군산 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 서산 지역의 instance 개수 :  98571 \n","\n","결측 날짜까지 만들어진 부여 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 금산 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 제천 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 태백 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 원주 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 철원 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 속초 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 파주 지역의 instance 개수 :  98575 \n","\n","결측 날짜까지 만들어진 양평 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 수원 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 동두천 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 서울 지역의 instance 개수 :  98570 \n","\n","결측 날짜까지 만들어진 인천 지역의 instance 개수 :  98570 \n","\n","결측 날짜까지 만들어진 광주 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 대구 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 부산 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 울산 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 대전 지역의 instance 개수 :  98569 \n","\n","결측 날짜까지 만들어진 세종 지역의 instance 개수 :  33590 \n","\n"]}]},{"cell_type":"code","source":["for _ in State_Name:\n","  df=pd.read_csv('/content/drive/MyDrive/2023 겨울학기 + 여름학기/B.I Contest/데이터/지역별 기상데이터 모음/결측값 채워진 df/filled_{}_df.csv'.format(ID[_][1]))\n","  print(\"결측 날짜까지 만들어진 {} 지역의 instance 개수 : \".format(_),df.shape[0], '\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qosVs74tfDFk","executionInfo":{"status":"ok","timestamp":1687236636488,"user_tz":-540,"elapsed":2724,"user":{"displayName":"정민균","userId":"02008085652330605669"}},"outputId":"4e56ded8-bf35-4fce-f3c6-583914a70489"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["결측 날짜까지 만들어진 경주 지역의 instance 개수 :  98659 \n","\n","결측 날짜까지 만들어진 구미 지역의 instance 개수 :  98571 \n","\n","결측 날짜까지 만들어진 거창 지역의 instance 개수 :  98571 \n","\n","결측 날짜까지 만들어진 밀양 지역의 instance 개수 :  98576 \n","\n","결측 날짜까지 만들어진 영광 지역의 instance 개수 :  98617 \n","\n","결측 날짜까지 만들어진 순천 지역의 instance 개수 :  98577 \n","\n","결측 날짜까지 만들어진 남원 지역의 instance 개수 :  98574 \n","\n","결측 날짜까지 만들어진 고창 지역의 instance 개수 :  98593 \n","\n","결측 날짜까지 만들어진 천안 지역의 instance 개수 :  98572 \n","\n","결측 날짜까지 만들어진 보은 지역의 instance 개수 :  98575 \n","\n","결측 날짜까지 만들어진 청주 지역의 instance 개수 :  98571 \n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ipKnETdgI-LC"},"execution_count":null,"outputs":[]}]}